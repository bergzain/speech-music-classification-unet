{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"/Users/zainhazzouri/projects/Bachelor_Thesis/Data/Kaggle\"\n",
    "SAMPLE_RATE = 22050 # sample rate of the audio file\n",
    "bit_depth = 16 # bit depth of the audio file\n",
    "hop_length = 512\n",
    "n_mfcc = 20 # number of MFCCs features\n",
    "n_fft=1024, # window size\n",
    "n_mels = 256 # number of mel bands to generate\n",
    "win_length = None # window length\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T14:59:55.143913Z",
     "end_time": "2023-04-15T14:59:55.145959Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T14:59:55.926881Z",
     "end_time": "2023-04-15T14:59:55.931798Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nbimporter\n",
    "from CNN_Model import AttentionResidualWaveUNet\n",
    "\n",
    "class SpeechMusicDataset(Dataset):\n",
    "    def __init__(self, music_waves, speech_waves, transform=None):\n",
    "        self.music_waves = music_waves\n",
    "        self.speech_waves = speech_waves\n",
    "        self.transform = transform\n",
    "        self.file_list = self.music_waves + self.speech_waves\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, _ = torchaudio.load(file_path)\n",
    "        label = 0 if 'music_wav' in file_path else 1\n",
    "\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "# Preprocessing function for the dataset\n",
    "def preprocess(waveform, target_length=8000, sample_rate=SAMPLE_RATE, n_mfcc=n_mfcc):\n",
    "    waveform_length = waveform.size(1)\n",
    "\n",
    "    if waveform_length < target_length:\n",
    "        num_padding = target_length - waveform_length\n",
    "        padding = torch.zeros(1, num_padding)\n",
    "        waveform = torch.cat((waveform, padding), 1)\n",
    "    elif waveform_length > target_length:\n",
    "        waveform = waveform[:, :target_length]\n",
    "\n",
    "    mfcc = torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=n_mfcc)(waveform)\n",
    "    return mfcc\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_built():  # if you have apple silicon mac\n",
    "    device = \"mps\"  # if it doesn't work try device = torch.device('mps')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Set the path to the folder containing the music and speech datasets\n",
    "AUDIO_DIR = \"/Users/zainhazzouri/projects/Bachelor_Thesis/Data/Kaggle/\"\n",
    "\n",
    "# Load the dataset\n",
    "music_waves = glob.glob(AUDIO_DIR + \"music_wav\" + \"/*.wav\")\n",
    "speech_waves = glob.glob(AUDIO_DIR + \"speech_wav\" + \"/*.wav\")\n",
    "transform = preprocess\n",
    "\n",
    "dataset = SpeechMusicDataset(music_waves, speech_waves, transform=transform)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pad_waveform(waveform, desired_length):\n",
    "    if waveform.shape[-1] < desired_length:\n",
    "        padding = desired_length - waveform.shape[-1]\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "music_waves = glob.glob(AUDIO_DIR + \"music_wav\" + \"/*.wav\")\n",
    "speech_waves = glob.glob(AUDIO_DIR + \"speech_wav\" + \"/*.wav\")\n",
    "transform = preprocess\n",
    "\n",
    "dataset = SpeechMusicDataset(music_waves, speech_waves, transform=transform)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = AttentionResidualWaveUNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-15T15:01:45.961018Z",
     "end_time": "2023-04-15T15:01:46.015334Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                               | 0/7 [00:00<?, ?it/s]/Users/zainhazzouri/miniforge3/envs/Bachelor_Thesis/lib/python3.8/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n",
      "Training:   0%|                                                               | 0/7 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 4 but got size 5 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Calculate loss\u001B[39;00m\n\u001B[1;32m     20\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, targets)\n",
      "File \u001B[0;32m~/miniforge3/envs/Bachelor_Thesis/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/projects/Bachelor_Thesis/Code/CNN_Model.ipynb:40\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m      1\u001B[0m {\n\u001B[1;32m      2\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcells\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m      3\u001B[0m   {\n\u001B[1;32m      4\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      5\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m      6\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m      7\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimport torch\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimport torch.nn as nn\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimport torch.nn.functional as F\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     11\u001B[0m    ],\n\u001B[1;32m     12\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: false,\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuteTime\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     15\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:45.235379Z\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     16\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:46.240321Z\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     17\u001B[0m     }\n\u001B[1;32m     18\u001B[0m    }\n\u001B[1;32m     19\u001B[0m   },\n\u001B[1;32m     20\u001B[0m   {\n\u001B[1;32m     21\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     22\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m,\n\u001B[1;32m     23\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m     24\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m     25\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass SelfAttention(nn.Module):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def __init__(self, in_channels):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     27\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        super(SelfAttention, self).__init__()\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     28\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.query = nn.Conv2d(in_channels, in_channels//8, 1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     29\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.key = nn.Conv2d(in_channels, in_channels//8, 1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.value = nn.Conv2d(in_channels, in_channels, 1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.gamma = nn.Parameter(torch.zeros(1))\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     32\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def forward(self, x):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        batch_size, channels, height, width = x.size()\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     35\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        query = self.query(x).view(batch_size, -1, height * width).permute(0, 2, 1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     36\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        key = self.key(x).view(batch_size, -1, height * width)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        attention = F.softmax(torch.bmm(query, key), dim=-1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        value = self.value(x).view(batch_size, -1, height * width)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     39\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        out = torch.bmm(value, attention.permute(0, 2, 1)).view(batch_size, channels, height, width)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m---> 40\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        out = self.gamma * out + x\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     41\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        return out\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     43\u001B[0m    ],\n\u001B[1;32m     44\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: false,\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuteTime\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     47\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:46.243086Z\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     48\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:46.244373Z\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     49\u001B[0m     }\n\u001B[1;32m     50\u001B[0m    }\n\u001B[1;32m     51\u001B[0m   },\n\u001B[1;32m     52\u001B[0m   {\n\u001B[1;32m     53\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     54\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m,\n\u001B[1;32m     55\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m     56\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass EncoderBlock(nn.Module):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     58\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def __init__(self, in_channels, out_channels):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     59\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        super(EncoderBlock, self).__init__()\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.bn = nn.BatchNorm2d(out_channels)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.relu = nn.ReLU(inplace=True)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def forward(self, x):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        x = self.conv(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        x = self.bn(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        x = self.relu(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        return x\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     69\u001B[0m    ],\n\u001B[1;32m     70\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: false,\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuteTime\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     73\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:46.246541Z\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     74\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:46.247434Z\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     75\u001B[0m     }\n\u001B[1;32m     76\u001B[0m    }\n\u001B[1;32m     77\u001B[0m   },\n\u001B[1;32m     78\u001B[0m   {\n\u001B[1;32m     79\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     80\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     81\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m     82\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m     83\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass DecoderBlock(nn.Module):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     84\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def __init__(self, in_channels, out_channels):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     85\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        super(DecoderBlock, self).__init__()\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.conv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, padding=1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     87\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.bn = nn.BatchNorm2d(out_channels)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.relu = nn.ReLU(inplace=True)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     89\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     90\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def forward(self, x):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     91\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        x = self.conv(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     92\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        x = self.bn(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        x = self.relu(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        return x\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     95\u001B[0m    ],\n\u001B[1;32m     96\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: false,\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuteTime\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m     99\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:46.466976Z\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    100\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:46.472227Z\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    101\u001B[0m     }\n\u001B[1;32m    102\u001B[0m    }\n\u001B[1;32m    103\u001B[0m   },\n\u001B[1;32m    104\u001B[0m   {\n\u001B[1;32m    105\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    106\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m5\u001B[39m,\n\u001B[1;32m    107\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m    108\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m    109\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclass AttentionResidualWaveUNet(nn.Module):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    110\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def __init__(self):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        super(AttentionResidualWaveUNet, self).__init__()\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    112\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    113\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Encoder\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    114\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.enc1 = EncoderBlock(1, 64)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.pool1 = nn.MaxPool2d(2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    116\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.enc2 = EncoderBlock(64, 128)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    117\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.pool2 = nn.MaxPool2d(2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.enc3 = EncoderBlock(128, 256)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    119\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.pool3 = nn.MaxPool2d(2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    120\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Middle\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    122\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.middle = EncoderBlock(256, 512)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    123\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.attention = SelfAttention(512)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    124\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Decoder\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    126\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    127\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.dec3 = DecoderBlock(256*2, 128)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    128\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.up2 = nn.ConvTranspose2d(128, 128, kernel_size=2, stride=2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.dec2 = DecoderBlock(128*2, 64)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    130\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.up1 = nn.ConvTranspose2d(64, 64, kernel_size=2,stride=2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    131\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        self.dec1 = DecoderBlock(64*2, 1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    132\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    133\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    def forward(self, x):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    134\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Encoder\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    135\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        enc1 = self.enc1(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        pool1 = self.pool1(enc1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    137\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        enc2 = self.enc2(pool1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    138\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        pool2 = self.pool2(enc2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        enc3 = self.enc3(pool2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    140\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        pool3 = self.pool3(enc3)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    141\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    142\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Middle\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        middle = self.middle(pool3)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        attention_out = self.attention(middle)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    145\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    146\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        # Decoder\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    147\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        up3 = self.up3(attention_out)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        merge3 = torch.cat([up3, enc3], dim=1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    149\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dec3 = self.dec3(merge3)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    150\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        up2 = self.up2(dec3)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    151\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        merge2 = torch.cat([up2, enc2], dim=1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    152\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dec2 = self.dec2(merge2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        up1 = self.up1(dec2)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    154\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        merge1 = torch.cat([up1, enc1], dim=1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    155\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        dec1 = self.dec1(merge1)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    156\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    157\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m        return dec1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    158\u001B[0m    ],\n\u001B[1;32m    159\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: false,\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuteTime\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    162\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:47.218440Z\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    163\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:47.220688Z\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    164\u001B[0m     }\n\u001B[1;32m    165\u001B[0m    }\n\u001B[1;32m    166\u001B[0m   },\n\u001B[1;32m    167\u001B[0m   {\n\u001B[1;32m    168\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    169\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m6\u001B[39m,\n\u001B[1;32m    170\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m    171\u001B[0m     {\n\u001B[1;32m    172\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstdout\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    173\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutput_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    174\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m    175\u001B[0m       \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch.Size([1, 1, 128, 128])\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    176\u001B[0m      ]\n\u001B[1;32m    177\u001B[0m     }\n\u001B[1;32m    178\u001B[0m    ],\n\u001B[1;32m    179\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [\n\u001B[1;32m    180\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m# Test the model\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    181\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif __name__ == \u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    182\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    model = AttentionResidualWaveUNet()\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    183\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    x = torch.randn(1, 1, 128, 128)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    184\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    y = model(x)\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    185\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m    print(y.shape)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    186\u001B[0m    ],\n\u001B[1;32m    187\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    188\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: false,\n\u001B[1;32m    189\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExecuteTime\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    190\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:48.591279Z\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    191\u001B[0m      \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mend_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2023-04-15T14:59:48.654515Z\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    192\u001B[0m     }\n\u001B[1;32m    193\u001B[0m    }\n\u001B[1;32m    194\u001B[0m   },\n\u001B[1;32m    195\u001B[0m   {\n\u001B[1;32m    196\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcell_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcode\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    197\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexecution_count\u001B[39m\u001B[38;5;124m\"\u001B[39m: null,\n\u001B[1;32m    198\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moutputs\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m    199\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m: [],\n\u001B[1;32m    200\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    201\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcollapsed\u001B[39m\u001B[38;5;124m\"\u001B[39m: false\n\u001B[1;32m    202\u001B[0m    }\n\u001B[1;32m    203\u001B[0m   }\n\u001B[1;32m    204\u001B[0m  ],\n\u001B[1;32m    205\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    206\u001B[0m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mkernelspec\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    207\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisplay_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPython 3\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    208\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    209\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython3\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    210\u001B[0m   },\n\u001B[1;32m    211\u001B[0m   \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlanguage_info\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    212\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcodemirror_mode\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mipython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m    215\u001B[0m    },\n\u001B[1;32m    216\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfile_extension\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.py\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    217\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmimetype\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext/x-python\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    218\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    219\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbconvert_exporter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    220\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpygments_lexer\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mipython2\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    221\u001B[0m    \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mversion\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m2.7.6\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    222\u001B[0m   }\n\u001B[1;32m    223\u001B[0m  },\n\u001B[1;32m    224\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbformat\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m    225\u001B[0m  \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnbformat_minor\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    226\u001B[0m }\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 1. Expected size 4 but got size 5 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch+1}/{num_epochs}\")\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # Add tqdm progress bar\n",
    "    for i, (inputs, targets) in enumerate(tqdm(train_loader, desc=\"Training\", ncols=100)):\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "print(\"Training finished.\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T16:51:33.788781Z",
     "end_time": "2023-04-14T16:51:43.344107Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7501\n",
      "Validation Accuracy: 38.46%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "\n",
    "#1. Average validation loss: This metric is calculated using the same loss function (`criterion`) used during training, which is CrossEntropyLoss in this case. The average validation loss is computed by summing the losses for all validation samples and then dividing by the number of validation samples. A lower average validation loss indicates better performance.\n",
    "#\n",
    "# 2. Validation accuracy: This metric measures the percentage of correctly classified samples in the validation set. The accuracy is calculated by counting the number of correct predictions, i.e., when the predicted label matches the true label, and then dividing by the total number of validation samples. A higher validation accuracy indicates better performance.\n",
    "#\n",
    "# These two metrics together provide a good evaluation of the model's performance on the validation set. The average validation loss helps assess the model's ability to minimize the loss function, while the validation accuracy measures how well the model is classifying the samples.\n",
    "\n",
    "\n",
    "def evaluate(val_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Update loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = evaluate(val_loader, model, criterion, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T16:51:56.611781Z",
     "end_time": "2023-04-14T16:51:56.749783Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"waveunet_speech_music_discrimination.pth\")\n",
    "print(\"Model saved.\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T16:50:18.240287Z",
     "end_time": "2023-04-14T16:50:18.285291Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 40, 20, 216]           1,040\n",
      "              ReLU-2          [-1, 40, 20, 216]               0\n",
      "            Conv2d-3          [-1, 80, 10, 108]          80,080\n",
      "              ReLU-4          [-1, 80, 10, 108]               0\n",
      "            Conv2d-5           [-1, 160, 5, 54]         320,160\n",
      "              ReLU-6           [-1, 160, 5, 54]               0\n",
      "   ConvTranspose2d-7          [-1, 80, 10, 108]         320,080\n",
      "              ReLU-8          [-1, 80, 10, 108]               0\n",
      "   ConvTranspose2d-9          [-1, 40, 20, 216]          80,040\n",
      "             ReLU-10          [-1, 40, 20, 216]               0\n",
      "  ConvTranspose2d-11          [-1, 40, 40, 432]          40,040\n",
      "             ReLU-12          [-1, 40, 40, 432]               0\n",
      "AdaptiveAvgPool2d-13             [-1, 40, 1, 1]               0\n",
      "           Linear-14                   [-1, 10]             410\n",
      "================================================================\n",
      "Total params: 841,850\n",
      "Trainable params: 841,850\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 19.12\n",
      "Params size (MB): 3.21\n",
      "Estimated Total Size (MB): 22.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    print(\"\\nModel summary:\")\n",
    "\n",
    "    original_device = device\n",
    "    if device == 'mps': # because MPS is not supported by torchsummary\n",
    "        device = 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    summary(model, input_size=(1, 40, 431), device=device)\n",
    "\n",
    "    if original_device == 'mps': # Restore original device\n",
    "        device = original_device\n",
    "        model.to(device)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nPlease install torchsummary to display the model summary. Use `pip install torchsummary`.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-14T16:50:23.103927Z",
     "end_time": "2023-04-14T16:50:23.161762Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
