{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "AUDIO_DIR = \"/Users/zainhazzouri/projects/Bachelor_Thesis/Data/Kaggle\"\n",
    "SAMPLE_RATE = 22050 # sample rate of the audio file\n",
    "bit_depth = 16 # bit depth of the audio file\n",
    "hop_length = 512\n",
    "n_mfcc = 20 # number of MFCCs features\n",
    "n_fft=1024, # window size\n",
    "n_mels = 256 # number of mel bands to generate\n",
    "win_length = None # window length\n",
    "\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "num_epochs = 50\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:04.091672Z",
     "end_time": "2023-04-17T17:01:04.093980Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:04.125669Z",
     "end_time": "2023-04-17T17:01:04.131881Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchaudio\n",
    "import glob\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nbimporter\n",
    "from CNN_Model import WaveUNet\n",
    "\n",
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, music_waves, speech_waves, mixed_waves, silence_waves, transform=None):\n",
    "        self.music_waves = music_waves\n",
    "        self.speech_waves = speech_waves\n",
    "        self.mixed_waves = mixed_waves\n",
    "        self.silence_waves = silence_waves\n",
    "        self.transform = transform\n",
    "        self.file_list = self.music_waves + self.speech_waves + self.mixed_waves + self.silence_waves\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_path = self.file_list[idx]\n",
    "        waveform, _ = torchaudio.load(file_path)\n",
    "        if 'music_wav' in file_path:\n",
    "            label = 0\n",
    "        elif 'speech_wav' in file_path:\n",
    "            label = 1\n",
    "        elif 'mixed_wav' in file_path:\n",
    "            label = 2\n",
    "        else:\n",
    "            label = 3\n",
    "\n",
    "        if self.transform:\n",
    "            waveform = self.transform(waveform)\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing function for the dataset\n",
    "def preprocess(waveform, target_length=8000, sample_rate=SAMPLE_RATE, n_mfcc=n_mfcc):\n",
    "    waveform_length = waveform.size(1)\n",
    "\n",
    "    if waveform_length < target_length:\n",
    "        num_padding = target_length - waveform_length\n",
    "        padding = torch.zeros(1, num_padding)\n",
    "        waveform = torch.cat((waveform, padding), 1)\n",
    "    elif waveform_length > target_length:\n",
    "        waveform = waveform[:, :target_length]\n",
    "\n",
    "    mfcc = torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=n_mfcc)(waveform)\n",
    "    return mfcc\n",
    "\n",
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_built():  # if you have apple silicon mac\n",
    "    device = \"mps\"  # if it doesn't work try device = torch.device('mps')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "# Set the path to the folder containing the music and speech datasets\n",
    "AUDIO_DIR = \"/Users/zainhazzouri/projects/Bachelor_Thesis/Data/Kaggle/\"\n",
    "\n",
    "# Load the dataset\n",
    "music_waves = glob.glob(AUDIO_DIR + \"music_wav\" + \"/*.wav\")\n",
    "speech_waves = glob.glob(AUDIO_DIR + \"speech_wav\" + \"/*.wav\")\n",
    "mixed_waves = glob.glob(AUDIO_DIR + \"Mix_wav\" + \"/*.wav\")\n",
    "silence_waves = glob.glob(AUDIO_DIR + \"silence_wav\" + \"/*.wav\")\n",
    "\n",
    "\n",
    "transform = preprocess\n",
    "\n",
    "# Load the dataset\n",
    "dataset = AudioDataset(music_waves, speech_waves, mixed_waves, silence_waves, transform=preprocess)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def pad_waveform(waveform, desired_length):\n",
    "    if waveform.shape[-1] < desired_length:\n",
    "        padding = desired_length - waveform.shape[-1]\n",
    "        waveform = torch.nn.functional.pad(waveform, (0, padding))\n",
    "    return waveform\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = WaveUNet(num_classes=4).to(device)  # Update num_classes to 4\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:04.352338Z",
     "end_time": "2023-04-17T17:01:05.637427Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/Users/zainhazzouri/miniforge3/envs/Bachelor_Thesis/lib/python3.8/site-packages/torchaudio/functional/functional.py:576: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n",
      "100%|██████████| 7/7 [00:01<00:00,  4.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.9838, Accuracy: 51.46%\n",
      "Validation Loss: 1.2126, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50, Loss: 0.8674, Accuracy: 52.43%\n",
      "Validation Loss: 0.8766, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50, Loss: 0.8996, Accuracy: 49.51%\n",
      "Validation Loss: 0.7724, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50, Loss: 0.8294, Accuracy: 52.43%\n",
      "Validation Loss: 0.8772, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50, Loss: 0.7686, Accuracy: 52.43%\n",
      "Validation Loss: 0.7798, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50, Loss: 0.7228, Accuracy: 44.66%\n",
      "Validation Loss: 0.6863, Validation Accuracy: 61.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50, Loss: 0.6979, Accuracy: 54.37%\n",
      "Validation Loss: 0.7783, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50, Loss: 0.7096, Accuracy: 52.43%\n",
      "Validation Loss: 0.6910, Validation Accuracy: 61.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50, Loss: 0.7268, Accuracy: 43.69%\n",
      "Validation Loss: 0.7195, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50, Loss: 0.6972, Accuracy: 52.43%\n",
      "Validation Loss: 0.7628, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50, Loss: 0.7066, Accuracy: 52.43%\n",
      "Validation Loss: 0.7105, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50, Loss: 0.7156, Accuracy: 42.72%\n",
      "Validation Loss: 0.7075, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50, Loss: 0.6986, Accuracy: 52.43%\n",
      "Validation Loss: 0.7175, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50, Loss: 0.7072, Accuracy: 52.43%\n",
      "Validation Loss: 0.7016, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50, Loss: 0.7111, Accuracy: 52.43%\n",
      "Validation Loss: 0.7102, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50, Loss: 0.6916, Accuracy: 52.43%\n",
      "Validation Loss: 0.7358, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50, Loss: 0.6674, Accuracy: 52.43%\n",
      "Validation Loss: 0.7005, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50, Loss: 0.6377, Accuracy: 52.43%\n",
      "Validation Loss: 0.6535, Validation Accuracy: 38.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50, Loss: 0.6002, Accuracy: 55.34%\n",
      "Validation Loss: 0.5676, Validation Accuracy: 88.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50, Loss: 0.6052, Accuracy: 73.79%\n",
      "Validation Loss: 0.4730, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50, Loss: 0.4404, Accuracy: 85.44%\n",
      "Validation Loss: 2.0857, Validation Accuracy: 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50, Loss: 0.4012, Accuracy: 89.32%\n",
      "Validation Loss: 0.4574, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50, Loss: 0.3084, Accuracy: 88.35%\n",
      "Validation Loss: 0.5083, Validation Accuracy: 73.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50, Loss: 0.3520, Accuracy: 86.41%\n",
      "Validation Loss: 0.6250, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50, Loss: 0.3412, Accuracy: 87.38%\n",
      "Validation Loss: 0.7697, Validation Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50, Loss: 0.2193, Accuracy: 91.26%\n",
      "Validation Loss: 0.5069, Validation Accuracy: 88.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50, Loss: 0.1367, Accuracy: 92.23%\n",
      "Validation Loss: 1.5187, Validation Accuracy: 73.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50, Loss: 0.1571, Accuracy: 94.17%\n",
      "Validation Loss: 0.6382, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50, Loss: 0.1157, Accuracy: 94.17%\n",
      "Validation Loss: 0.7040, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50, Loss: 0.1129, Accuracy: 94.17%\n",
      "Validation Loss: 2.5732, Validation Accuracy: 65.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50, Loss: 0.0752, Accuracy: 97.09%\n",
      "Validation Loss: 0.6982, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50, Loss: 0.0679, Accuracy: 97.09%\n",
      "Validation Loss: 1.6551, Validation Accuracy: 73.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50, Loss: 0.0371, Accuracy: 98.06%\n",
      "Validation Loss: 0.9659, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50, Loss: 0.0304, Accuracy: 98.06%\n",
      "Validation Loss: 1.7005, Validation Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50, Loss: 0.0175, Accuracy: 99.03%\n",
      "Validation Loss: 2.0333, Validation Accuracy: 76.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50, Loss: 0.0130, Accuracy: 99.03%\n",
      "Validation Loss: 1.8766, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50, Loss: 0.0092, Accuracy: 100.00%\n",
      "Validation Loss: 1.9472, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50, Loss: 0.0023, Accuracy: 100.00%\n",
      "Validation Loss: 2.0702, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50, Loss: 0.0006, Accuracy: 100.00%\n",
      "Validation Loss: 2.3868, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50, Loss: 0.0006, Accuracy: 100.00%\n",
      "Validation Loss: 2.6545, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50, Loss: 0.0001, Accuracy: 100.00%\n",
      "Validation Loss: 2.7549, Validation Accuracy: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 2.9355, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.0686, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.1738, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.2605, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.3559, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.4527, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 15.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.5391, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.6185, Validation Accuracy: 80.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50, Loss: 0.0000, Accuracy: 100.00%\n",
      "Validation Loss: 3.7274, Validation Accuracy: 80.77%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(tqdm(train_loader)):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / (i + 1)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, labels) in enumerate(val_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_epoch_loss = val_running_loss / (i + 1)\n",
    "        val_epoch_acc = 100 * val_correct / val_total\n",
    "        print(f\"Validation Loss: {val_epoch_loss:.4f}, Validation Accuracy: {val_epoch_acc:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:05.640121Z",
     "end_time": "2023-04-17T17:01:35.587398Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.7274\n",
      "Validation Accuracy: 80.77%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation function\n",
    "\n",
    "#1. Average validation loss: This metric is calculated using the same loss function (`criterion`) used during training, which is CrossEntropyLoss in this case. The average validation loss is computed by summing the losses for all validation samples and then dividing by the number of validation samples. A lower average validation loss indicates better performance.\n",
    "#\n",
    "# 2. Validation accuracy: This metric measures the percentage of correctly classified samples in the validation set. The accuracy is calculated by counting the number of correct predictions, i.e., when the predicted label matches the true label, and then dividing by the total number of validation samples. A higher validation accuracy indicates better performance.\n",
    "#\n",
    "# These two metrics together provide a good evaluation of the model's performance on the validation set. The average validation loss helps assess the model's ability to minimize the loss function, while the validation accuracy measures how well the model is classifying the samples.\n",
    "\n",
    "\n",
    "def evaluate(val_loader, model, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate loss\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Update loss\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "\n",
    "    # Calculate average loss and accuracy\n",
    "    avg_loss = running_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Evaluate the model\n",
    "val_loss, val_accuracy = evaluate(val_loader, model, criterion, device)\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2f}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:35.585236Z",
     "end_time": "2023-04-17T17:01:35.700051Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), \"waveunet_speech_music_discrimination.pth\")\n",
    "print(\"Model saved.\")\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:35.709323Z",
     "end_time": "2023-04-17T17:01:35.711771Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:35.711537Z",
     "end_time": "2023-04-17T17:01:35.713565Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model summary:\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 40, 20, 216]           1,040\n",
      "              ReLU-2          [-1, 40, 20, 216]               0\n",
      "            Conv2d-3          [-1, 80, 10, 108]          80,080\n",
      "              ReLU-4          [-1, 80, 10, 108]               0\n",
      "            Conv2d-5           [-1, 160, 5, 54]         320,160\n",
      "              ReLU-6           [-1, 160, 5, 54]               0\n",
      "   ConvTranspose2d-7          [-1, 80, 10, 108]         320,080\n",
      "              ReLU-8          [-1, 80, 10, 108]               0\n",
      "   ConvTranspose2d-9          [-1, 40, 20, 216]          80,040\n",
      "             ReLU-10          [-1, 40, 20, 216]               0\n",
      "  ConvTranspose2d-11          [-1, 40, 40, 432]          40,040\n",
      "             ReLU-12          [-1, 40, 40, 432]               0\n",
      "AdaptiveAvgPool2d-13             [-1, 40, 1, 1]               0\n",
      "           Linear-14                    [-1, 4]             164\n",
      "================================================================\n",
      "Total params: 841,604\n",
      "Trainable params: 841,604\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.07\n",
      "Forward/backward pass size (MB): 19.12\n",
      "Params size (MB): 3.21\n",
      "Estimated Total Size (MB): 22.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Show model summary\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    print(\"\\nModel summary:\")\n",
    "\n",
    "    original_device = device\n",
    "    if device == 'mps': # because MPS is not supported by torchsummary\n",
    "        device = 'cpu'\n",
    "    model.to(device)\n",
    "\n",
    "    summary(model, input_size=(1, 40, 431), device=device)\n",
    "\n",
    "    if original_device == 'mps': # Restore original device\n",
    "        device = original_device\n",
    "        model.to(device)\n",
    "\n",
    "except ImportError:\n",
    "    print(\"\\nPlease install torchsummary to display the model summary. Use `pip install torchsummary`.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T17:01:35.714504Z",
     "end_time": "2023-04-17T17:01:35.765253Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
