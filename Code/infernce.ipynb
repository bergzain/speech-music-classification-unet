{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import librosa\n",
    "from cnn_model import CNNModel\n",
    "\n",
    "from datapreprocessing import AudioProcessor\n",
    "from torch.utils.data import Dataset\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:27:32.696262Z",
     "start_time": "2023-08-14T11:27:32.692632Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# audio_file_path = \"/Users/zainhazzouri/Desktop/egp1.mp3\"\n",
    "audio_file_path = \"/Users/zainhazzouri/projects/Bachelor_Thesis/Data/test/music_wav/beatles.wav\"\n",
    "\n",
    "SAMPLE_RATE = 22050 # sample rate of the audio file\n",
    "bit_depth = 16 # bit depth of the audio file\n",
    "hop_length = 512\n",
    "n_mfcc = 20 # number of MFCCs features\n",
    "n_fft=1024, # window size\n",
    "n_mels = 64 # number of mel bands to generate\n",
    "win_length = None # window length\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:29:07.809348Z",
     "start_time": "2023-08-14T11:29:07.803349Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_built():  # if you have apple silicon mac\n",
    "    device = \"mps\"  # if it doesn't work try device = torch.device('mps')\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "print(f\"Using {device}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:29:08.163182Z",
     "start_time": "2023-08-14T11:29:08.159540Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "CNNModel(\n  (Maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Conv1): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Conv2): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Conv3): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Conv4): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Conv5): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Up5): up_conv(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='nearest')\n      (1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n  )\n  (Att5): Attention_block(\n    (W_g): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (Up_conv5): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Up4): up_conv(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='nearest')\n      (1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n  )\n  (Att4): Attention_block(\n    (W_g): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (Up_conv4): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Up3): up_conv(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='nearest')\n      (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n  )\n  (Att3): Attention_block(\n    (W_g): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (Up_conv3): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Up2): up_conv(\n    (up): Sequential(\n      (0): Upsample(scale_factor=2.0, mode='nearest')\n      (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ReLU(inplace=True)\n    )\n  )\n  (Att2): Attention_block(\n    (W_g): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (W_x): Sequential(\n      (0): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (psi): Sequential(\n      (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n      (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): Sigmoid()\n    )\n    (relu): ReLU(inplace=True)\n  )\n  (Up_conv2): conv_block(\n    (conv): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ReLU(inplace=True)\n      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (5): ReLU(inplace=True)\n    )\n  )\n  (Conv_1x1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n  (fc): Linear(in_features=14336, out_features=4, bias=True)\n  (softmax): Softmax(dim=1)\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNModel().to(device)\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval() # some parts are turned off for evaluation because we don't need them"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:29:08.658441Z",
     "start_time": "2023-08-14T11:29:08.367112Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def split_waveform(waveform, sample_rate):\n",
    "    segment_length = sample_rate # 1 second segments\n",
    "    num_segments = waveform.shape[-1] // segment_length\n",
    "    segments = []\n",
    "\n",
    "    for i in range(num_segments):\n",
    "        start = i * segment_length\n",
    "        end = start + segment_length\n",
    "        segments.append(waveform[:, start:end])\n",
    "\n",
    "    return segments"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:29:08.787958Z",
     "start_time": "2023-08-14T11:29:08.784184Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "audio_processor = AudioProcessor(audio_file_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:29:09.526832Z",
     "start_time": "2023-08-14T11:29:09.518591Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def classify_audio_file_segments(audio_file_path, audio_processor):\n",
    "    file_ext = os.path.splitext(audio_file_path)[1].lower() # file extension\n",
    "\n",
    "    if file_ext == '.mp3':\n",
    "        waveform, sample_rate = librosa.load(audio_file_path, sr=SAMPLE_RATE)\n",
    "        waveform = torch.from_numpy(waveform).unsqueeze(0)\n",
    "    else:\n",
    "        waveform, sample_rate = torchaudio.load(audio_file_path)\n",
    "\n",
    "    segments = split_waveform(waveform, sample_rate)\n",
    "\n",
    "    segment_classifications = []\n",
    "\n",
    "    for segment in segments:\n",
    "        # Apply the sequence of operations\n",
    "        segment = audio_processor._resample_if_necessary(segment, sample_rate)\n",
    "        segment = audio_processor._mix_down_if_necessary(segment)\n",
    "        segment = audio_processor._right_pad_if_necessary(segment)\n",
    "        segment = audio_processor._cut_if_necessary(segment)\n",
    "\n",
    "        # Apply the MFCC transformation directly\n",
    "        mfcc = torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=audio_processor.n_mfcc)(segment)\n",
    "        mfcc = mfcc.to(audio_processor.device).unsqueeze(0)\n",
    "        output = model(mfcc)\n",
    "        _, predicted_class = torch.max(output, 1)\n",
    "        segment_classifications.append(predicted_class.item())\n",
    "\n",
    "    return segment_classifications"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:29:10.000888Z",
     "start_time": "2023-08-14T11:29:09.997064Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Time | End Time | Class\n",
      "----------------------------\n",
      "00:00:00 | 00:00:07 | 1\n",
      "00:00:07 | 00:00:44 | 2\n",
      "00:00:44 | 00:21:16 | 1\n",
      "00:21:16 | 00:21:17 | 2\n",
      "00:21:17 | 00:21:19 | 1\n",
      "00:21:19 | 00:21:20 | 2\n",
      "00:21:20 | 00:26:50 | 1\n",
      "00:26:50 | 00:26:51 | 2\n",
      "00:26:51 | 00:42:05 | 1\n",
      "00:42:05 | 00:42:06 | 2\n",
      "00:42:06 | 00:43:25 | 1\n",
      "00:43:25 | 00:43:26 | 2\n",
      "00:43:26 | 00:43:45 | 1\n",
      "00:43:45 | 00:43:46 | 2\n",
      "00:43:46 | 00:44:13 | 1\n",
      "00:44:13 | 00:44:14 | 2\n",
      "00:44:14 | 00:44:20 | 1\n",
      "00:44:20 | 00:44:21 | 2\n",
      "00:44:21 | 00:44:49 | 1\n",
      "00:44:49 | 00:44:50 | 0\n",
      "00:44:50 | 00:45:31 | 1\n",
      "00:45:31 | 00:45:32 | 2\n",
      "00:45:32 | 00:46:39 | 1\n",
      "00:46:39 | 00:46:40 | 2\n",
      "00:46:40 | 00:47:00 | 1\n",
      "00:47:00 | 00:47:01 | 2\n",
      "00:47:01 | 00:47:59 | 1\n",
      "00:47:59 | 00:48:00 | 2\n",
      "00:48:00 | 00:49:41 | 1\n",
      "00:49:41 | 00:49:42 | 2\n",
      "00:49:42 | 00:55:30 | 1\n",
      "00:55:30 | 00:55:31 | 2\n",
      "00:55:31 | 00:59:21 | 1\n",
      "00:59:21 | 00:59:23 | 2\n",
      "00:59:23 | 01:01:10 | 1\n",
      "01:01:10 | 01:01:11 | 2\n",
      "01:01:11 | 01:01:33 | 1\n",
      "01:01:33 | 01:01:34 | 2\n",
      "01:01:34 | 01:04:30 | 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def format_time(seconds):\n",
    "    hours, remainder = divmod(seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    return f\"{hours:02d}:{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "\n",
    "def generate_classification_table(classification_results, segment_duration=1):\n",
    "    table = []\n",
    "    current_label = classification_results[0]\n",
    "    start_time = 0\n",
    "\n",
    "    for i, label in enumerate(classification_results[1:], 1):\n",
    "        if label != current_label:\n",
    "            table.append([format_time(start_time), format_time(i * segment_duration), current_label])\n",
    "            start_time = i * segment_duration\n",
    "            current_label = label\n",
    "\n",
    "    table.append([format_time(start_time), format_time(len(classification_results) * segment_duration), current_label])\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def save_classification_table_to_csv(table, output_file):\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['Start Time', 'End Time', 'Class'])\n",
    "        for row in table:\n",
    "            csvwriter.writerow(row)\n",
    "\n",
    "# print(audio_file_path)\n",
    "classification_results = classify_audio_file_segments(audio_file_path, audio_processor)\n",
    "table = generate_classification_table(classification_results)\n",
    "\n",
    "# Save the table to a CSV file\n",
    "save_classification_table_to_csv(table, \"classification_table.csv\")\n",
    "\n",
    "# Print the table\n",
    "print(\"Start Time | End Time | Class\")\n",
    "print(\"-\" * 28)\n",
    "for row in table:\n",
    "    print(f\"{row[0]} | {row[1]} | {row[2]}\")\n",
    "\n",
    "\n",
    "# music_wav = 0, speech_wav = 1, Mix_wav = 2, silence_wav = 3\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:32:51.274882Z",
     "start_time": "2023-08-14T11:31:26.642505Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['00:00:00', '00:00:07', 1], ['00:00:07', '00:00:44', 2], ['00:00:44', '00:21:16', 1], ['00:21:16', '00:21:17', 2], ['00:21:17', '00:21:19', 1], ['00:21:19', '00:21:20', 2], ['00:21:20', '00:26:50', 1], ['00:26:50', '00:26:51', 2], ['00:26:51', '00:42:05', 1], ['00:42:05', '00:42:06', 2], ['00:42:06', '00:43:25', 1], ['00:43:25', '00:43:26', 2], ['00:43:26', '00:43:45', 1], ['00:43:45', '00:43:46', 2], ['00:43:46', '00:44:13', 1], ['00:44:13', '00:44:14', 2], ['00:44:14', '00:44:20', 1], ['00:44:20', '00:44:21', 2], ['00:44:21', '00:44:49', 1], ['00:44:49', '00:44:50', 0], ['00:44:50', '00:45:31', 1], ['00:45:31', '00:45:32', 2], ['00:45:32', '00:46:39', 1], ['00:46:39', '00:46:40', 2], ['00:46:40', '00:47:00', 1], ['00:47:00', '00:47:01', 2], ['00:47:01', '00:47:59', 1], ['00:47:59', '00:48:00', 2], ['00:48:00', '00:49:41', 1], ['00:49:41', '00:49:42', 2], ['00:49:42', '00:55:30', 1], ['00:55:30', '00:55:31', 2], ['00:55:31', '00:59:21', 1], ['00:59:21', '00:59:23', 2], ['00:59:23', '01:01:10', 1], ['01:01:10', '01:01:11', 2], ['01:01:11', '01:01:33', 1], ['01:01:33', '01:01:34', 2], ['01:01:34', '01:04:30', 1]]\n"
     ]
    }
   ],
   "source": [
    "audio_processor = AudioProcessor(audio_file_path)\n",
    "\n",
    "classification_results = classify_audio_file_segments(audio_file_path, audio_processor)\n",
    "table = generate_classification_table(classification_results)\n",
    "print(table)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T11:34:22.494901Z",
     "start_time": "2023-08-14T11:32:51.268435Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-27T20:13:18.874543Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
